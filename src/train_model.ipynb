{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### This is a sample notebook showing how to train the ML models for XPFS/XPCS single-photon counting experiments. For the training, please extract the dataset at: https://zenodo.org/record/6643622 to the ml_xpfs folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import h5py\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "from scipy.optimize import minimize\n",
    "from scipy.misc import derivative\n",
    "\n",
    "from tqdm import tqdm\n",
    "from unet_model import *\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "hf = h5py.File('../XPFS_data/high_kbar/high_kbar.h5', 'r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following three cells breaks down the h5 file structure. Please note that the valid and test data have 18 datasets respectively. Each dataset corresponds to a particular contrast level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<KeysViewHDF5 ['test', 'train', 'valid']>\n"
     ]
    }
   ],
   "source": [
    "print(hf.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<KeysViewHDF5 ['train_detector', 'train_photon_map']>\n"
     ]
    }
   ],
   "source": [
    "print(hf['train'].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<KeysViewHDF5 ['valid_detector_0.1', 'valid_detector_0.15', 'valid_detector_0.2', 'valid_detector_0.25', 'valid_detector_0.3', 'valid_detector_0.35', 'valid_detector_0.4', 'valid_detector_0.45', 'valid_detector_0.5', 'valid_detector_0.55', 'valid_detector_0.6', 'valid_detector_0.65', 'valid_detector_0.7', 'valid_detector_0.75', 'valid_detector_0.8', 'valid_detector_0.85', 'valid_detector_0.9', 'valid_detector_0.95', 'valid_photon_map_0.1', 'valid_photon_map_0.15', 'valid_photon_map_0.2', 'valid_photon_map_0.25', 'valid_photon_map_0.3', 'valid_photon_map_0.35', 'valid_photon_map_0.4', 'valid_photon_map_0.45', 'valid_photon_map_0.5', 'valid_photon_map_0.55', 'valid_photon_map_0.6', 'valid_photon_map_0.65', 'valid_photon_map_0.7', 'valid_photon_map_0.75', 'valid_photon_map_0.8', 'valid_photon_map_0.85', 'valid_photon_map_0.9', 'valid_photon_map_0.95']>\n"
     ]
    }
   ],
   "source": [
    "print(hf['valid'].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom callback for contrast calculation on 18 validation sets every 10 epochs. \n",
    "# This is a useful check that the model is actually learning contrast and not just MSE \n",
    "\n",
    "class ContrastEvaluation(Callback):\n",
    "    def __init__(self):\n",
    "        super(Callback, self).__init__()\n",
    "\n",
    "    def on_epoch_end(self,epochs,logs=None):\n",
    "                \n",
    "        # Validation Set Contrast \n",
    "        if (epochs % 10 == 0):\n",
    "            \n",
    "            true = list(np.round(np.linspace(0.1, 0.95, 18), 2))\n",
    "            \n",
    "            ml_pred = []\n",
    "            \n",
    "            for element in true:\n",
    "                X_ADU_test = np.array(hf['valid']['valid_detector_' + str(element)])                 \n",
    "                photon_map = np.round(model.predict(X_ADU_test))\n",
    "                data = np.reshape(photon_map, (len(photon_map), -1))\n",
    "                k = np.reshape(data, -1)\n",
    "                kbar = np.repeat(np.mean(data, axis=1),900)\n",
    "                result = minimize(nll,0.8,args=(k,kbar),bounds=((0.001,1.0),))\n",
    "                ml_pred.append(result.x[0])\n",
    "                \n",
    "            corr, _ = pearsonr(ml_pred, true)\n",
    "            print(str(epochs))\n",
    "            print(\"Correlation: \", corr)\n",
    "            \n",
    "            plt.scatter(true, ml_pred)\n",
    "            plt.plot(np.linspace(0,1), np.linspace(0,1), color='red')\n",
    "            plt.xlabel(\"True\")\n",
    "            plt.ylabel(\"Predicted\")\n",
    "            plt.xlim(0,1)\n",
    "            plt.ylim(0,1)\n",
    "            plt.show()\n",
    "        \n",
    "            print(\"------------------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training data; already normalized to a photon ADU = 340\n",
    "X_train_ADU = np.array(hf['train']['train_detector'])\n",
    "X_train_GT = np.array(hf['train']['train_photon_map'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"U-Net\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 90, 90, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 90, 90, 8)    80          ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 90, 90, 8)   32          ['conv2d[0][0]']                 \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " tf.nn.relu (TFOpLambda)        (None, 90, 90, 8)    0           ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 90, 90, 8)    584         ['tf.nn.relu[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 90, 90, 8)   32          ['conv2d_1[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " tf.nn.relu_1 (TFOpLambda)      (None, 90, 90, 8)    0           ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2D)   (None, 30, 30, 8)    0           ['tf.nn.relu_1[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 30, 30, 16)   1168        ['max_pooling2d[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 30, 30, 16)  64          ['conv2d_2[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " tf.nn.relu_2 (TFOpLambda)      (None, 30, 30, 16)   0           ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 30, 30, 16)   2320        ['tf.nn.relu_2[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 30, 30, 16)  64          ['conv2d_3[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " tf.nn.relu_3 (TFOpLambda)      (None, 30, 30, 16)   0           ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPooling2D)  (None, 10, 10, 16)  0           ['tf.nn.relu_3[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 10, 10, 32)   4640        ['max_pooling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 10, 10, 32)  128         ['conv2d_4[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " tf.nn.relu_4 (TFOpLambda)      (None, 10, 10, 32)   0           ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 10, 10, 32)   9248        ['tf.nn.relu_4[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 10, 10, 32)  128         ['conv2d_5[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " tf.nn.relu_5 (TFOpLambda)      (None, 10, 10, 32)   0           ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPooling2D)  (None, 5, 5, 32)    0           ['tf.nn.relu_5[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 5, 5, 64)     18496       ['max_pooling2d_2[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 5, 5, 64)    256         ['conv2d_6[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " tf.nn.relu_6 (TFOpLambda)      (None, 5, 5, 64)     0           ['batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 5, 5, 64)     36928       ['tf.nn.relu_6[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 5, 5, 64)    256         ['conv2d_7[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " tf.nn.relu_7 (TFOpLambda)      (None, 5, 5, 64)     0           ['batch_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_transpose (Conv2DTransp  (None, 10, 10, 32)  18464       ['tf.nn.relu_7[0][0]']           \n",
      " ose)                                                                                             \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 10, 10, 64)   0           ['conv2d_transpose[0][0]',       \n",
      "                                                                  'tf.nn.relu_5[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, 10, 10, 32)   18464       ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 10, 10, 32)  128         ['conv2d_8[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " tf.nn.relu_8 (TFOpLambda)      (None, 10, 10, 32)   0           ['batch_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)              (None, 10, 10, 32)   9248        ['tf.nn.relu_8[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_9 (BatchNo  (None, 10, 10, 32)  128         ['conv2d_9[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " tf.nn.relu_9 (TFOpLambda)      (None, 10, 10, 32)   0           ['batch_normalization_9[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_transpose_1 (Conv2DTran  (None, 30, 30, 16)  4624        ['tf.nn.relu_9[0][0]']           \n",
      " spose)                                                                                           \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 30, 30, 32)   0           ['conv2d_transpose_1[0][0]',     \n",
      "                                                                  'tf.nn.relu_3[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)             (None, 30, 30, 16)   4624        ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_10 (BatchN  (None, 30, 30, 16)  64          ['conv2d_10[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " tf.nn.relu_10 (TFOpLambda)     (None, 30, 30, 16)   0           ['batch_normalization_10[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)             (None, 30, 30, 16)   2320        ['tf.nn.relu_10[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_11 (BatchN  (None, 30, 30, 16)  64          ['conv2d_11[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " tf.nn.relu_11 (TFOpLambda)     (None, 30, 30, 16)   0           ['batch_normalization_11[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)             (None, 30, 30, 1)    17          ['tf.nn.relu_11[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 132,569\n",
      "Trainable params: 131,897\n",
      "Non-trainable params: 672\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8282722bd83d4f28940f863600e0b79c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0epoch [00:00, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Correlation:  0.9977171399608573\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "input_shape = (90, 90, 1)\n",
    "\n",
    "ce = ContrastEvaluation()\n",
    "\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "model = build_unet(input_shape)\n",
    "model.summary()\n",
    "model.compile(loss='mse', metrics='mse', optimizer=opt)\n",
    "history = model.fit(X_train_ADU, X_train_GT, validation_split = 0.1, epochs=50, shuffle=True,batch_size=128, verbose=0, callbacks=[ce, TqdmCallbackFix(verbose=0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training and validation loss history \n",
    "figure(figsize=(8, 8), dpi=80)\n",
    "plt.plot(history.history['mse'], label = 'Training Mean Squared Error')\n",
    "plt.plot(history.history['val_mse'], label = 'Validation Mean Squared Error')\n",
    "plt.xticks(fontsize=15)\n",
    "plt.yticks(fontsize=15)\n",
    "plt.gca().set_aspect('equal', adjustable='box')\n",
    "plt.legend(fontsize=16)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
